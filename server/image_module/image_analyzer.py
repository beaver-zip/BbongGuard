"""
Google Cloud Vision API + Video Intelligence API ê¸°ë°˜ ì´ë¯¸ì§€ ë¶„ì„ ëª¨ë“ˆ
- ì¸ë„¤ì¼ TEXT_DETECTION (OCR ê¸°ë°˜ ë‚šì‹œì„± íƒì§€)
- ì˜ìƒ ì „ì²´ Label Detection (ë‚´ìš© ë¶ˆì¼ì¹˜ íƒì§€)
"""

import logging
import time
import requests
import asyncio
import os
import tempfile
import yt_dlp
import re
from typing import List, Dict, Any, Optional
from google.cloud import vision


from ..shared.schemas import Claim
from ..shared.logger_utils import log_execution
from .schemas import ImageAnalysisRequest, ImageModuleResult, ClaimVerdict
from ..shared.llm_client import get_llm_client
from ..resources.prompts import get_thumbnail_analysis_prompt
from ..resources.keywords import CLICKBAIT_KEYWORDS

logger = logging.getLogger(__name__)


class ImageAnalyzer:
    """
    Google Cloud Vision API + Video Intelligence APIë¥¼ ì‚¬ìš©í•˜ì—¬
    ì¸ë„¤ì¼ ë‚šì‹œì„± ë° ì˜ìƒ ë‚´ìš© ë¶ˆì¼ì¹˜ë¥¼ ë¶„ì„í•˜ëŠ” í´ë˜ìŠ¤
    """

    def __init__(self):
        """ImageAnalyzer ì´ˆê¸°í™”"""
        logger.info("ImageAnalyzer(Google Vision + GPT-4o-mini) ì´ˆê¸°í™” ì‹œì‘...")
        
        # Google Cloud Vision í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            from ..config import Config
            if Config.GOOGLE_APPLICATION_CREDENTIALS_PATH:
                os.environ["GOOGLE_APPLICATION_CREDENTIALS"] = Config.GOOGLE_APPLICATION_CREDENTIALS_PATH
                logger.info(f"Google Cloud Credentials ì„¤ì •: {Config.GOOGLE_APPLICATION_CREDENTIALS_PATH}")

            self.vision_client = vision.ImageAnnotatorClient()
            logger.info("Google Cloud Vision API ì—°ê²° ì„±ê³µ")
        except Exception as e:
            logger.error(f"Google Cloud Vision API ì—°ê²° ì‹¤íŒ¨: {e}")
            self.vision_client = None



    @log_execution(module_name="image", step_name="full_analysis")
    async def analyze(self, request: ImageAnalysisRequest) -> ImageModuleResult:
        """
        ì´ë¯¸ì§€ ë¶„ì„ ìˆ˜í–‰ (ì¸ë„¤ì¼ TEXT_DETECTION + ì˜ìƒ ì „ì²´ ë¶„ì„)
        """
        start_time = time.time()
        logger.info(f"ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {request.video_id}")

        # [ì•ˆì „ ì¥ì¹˜] í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìœ¼ë©´ ë¹ ë¥¸ ì‹¤íŒ¨ ì²˜ë¦¬
        if not self.vision_client:
             return ImageModuleResult(
                modality="image",
                video_id=request.video_id,
                analysis_summary="Google Cloud API ì„¤ì • ì˜¤ë¥˜ë¡œ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                claims=[],
                processing_time_ms=(time.time() - start_time) * 1000,
                status="error",
                error_message="Google Cloud Client not initialized"
            )

        thumbnail_text_result = {}
        video_analysis_result = {}
        summary = "ë¶„ì„ ì‹¤íŒ¨"
        temp_video_path = None

        try:
            # 1. ì¸ë„¤ì¼ TEXT_DETECTION (Vision API OCR)
            thumbnail_url = f"https://img.youtube.com/vi/{request.video_id}/maxresdefault.jpg"
            logger.info("Step 1/3: ì¸ë„¤ì¼ TEXT_DETECTION ë¶„ì„ ì¤‘...")
            
            try:
                thumbnail_text_result = await self._analyze_thumbnail_text(thumbnail_url)
            except Exception as e:
                logger.warning(f"ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                thumbnail_text_result = {"error": str(e)}

            # 2. ì¸ë„¤ì¼ 2ë‹¨ê³„ ë¶„ì„
            text_size_ratio = thumbnail_text_result.get("text_size_ratio", 0.0)

            if thumbnail_text_result.get("error"):
                # TEXT_DETECTION ì‹¤íŒ¨ ì‹œ
                thumbnail_analysis = {
                    "stage": "error",
                    "is_fake": False,
                    "reason": f"ì¸ë„¤ì¼ ë¶„ì„ ì‹¤íŒ¨: {thumbnail_text_result['error']}"
                }
            else:
                # Stage 1: OCR ê¸°ë°˜ 1ì°¨ í•„í„°ë§
                keyword_check = self._check_clickbait_keywords(
                    thumbnail_text_result.get("extracted_text", "")
                )

                # ê·œì¹™: í…ìŠ¤íŠ¸ 20% ë¯¸ë§Œì´ê³  í‚¤ì›Œë“œ ì—†ìœ¼ë©´ í†µê³¼
                if text_size_ratio < 0.2 and not keyword_check["has_clickbait"]:
                    logger.info("âœ… Stage 1 í†µê³¼: ì¸ë„¤ì¼ ì •ìƒ (í…ìŠ¤íŠ¸ ì ìŒ + í‚¤ì›Œë“œ ì—†ìŒ)")
                    thumbnail_analysis = {
                        "stage": "stage1_pass",
                        "is_fake": False,
                        "text_size_ratio": text_size_ratio,
                        "matched_keywords": [],
                        "reason": "í…ìŠ¤íŠ¸ ë©´ì  20% ë¯¸ë§Œ, ìê·¹ì  í‚¤ì›Œë“œ ì—†ìŒ"
                    }
                # í…ìŠ¤íŠ¸ 20% ì´ìƒì´ê³  í‚¤ì›Œë“œ ìˆìœ¼ë©´ Stage 2 ì§„í–‰
                elif text_size_ratio >= 0.2 and keyword_check["has_clickbait"]:
                    logger.info("âš ï¸  Stage 1 ì˜ì‹¬ â†’ Stage 2 GPT Vision ë¶„ì„ ìˆ˜í–‰")
                    vision_result = await self._analyze_thumbnail_with_vision(
                        thumbnail_url,
                        thumbnail_text_result.get("extracted_text", ""),
                        keyword_check["matched_keywords"]
                    )
                    thumbnail_analysis = {
                        "stage": "stage2_vision",
                        "is_fake": vision_result.get("fake_news_rating", "Safe") in ["Danger", "Warning"],
                        "text_size_ratio": text_size_ratio,
                        "matched_keywords": keyword_check["matched_keywords"],
                        "vision_analysis": vision_result,
                        "reason": vision_result.get("reason", "GPT Vision ë¶„ì„ ì™„ë£Œ")
                    }
                else:
                    # ì¤‘ê°„ ì¼€ì´ìŠ¤: í…ìŠ¤íŠ¸ëŠ” ë§ì§€ë§Œ í‚¤ì›Œë“œ ì—†ìŒ, ë˜ëŠ” ê·¸ ë°˜ëŒ€
                    logger.info("â„¹ï¸  Stage 1: ê²½ê³„ ì¼€ì´ìŠ¤ (ì¶”ê°€ ë¶„ì„ ì—†ì´ ì •ìƒ ì²˜ë¦¬)")
                    thumbnail_analysis = {
                        "stage": "stage1_borderline",
                        "is_fake": False,
                        "text_size_ratio": text_size_ratio,
                        "matched_keywords": keyword_check["matched_keywords"],
                        "reason": "ê¸°ì¤€ ë¯¸ë‹¬ë¡œ ì •ìƒ ì²˜ë¦¬"
                    }
            # 3. ìµœì¢… í‰ê°€ (ì¸ë„¤ì¼ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜)
            is_fake = thumbnail_analysis.get("is_fake", False)
            
            # ì¸ë„¤ì¼ ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ ì ìˆ˜ í• ë‹¹ (0.0 ~ 1.0)
            # Safe: 0.0, Warning: 0.5, Danger: 1.0
            image_contradiction_score = 0.0
            
            if is_fake:
                # Stage 2ì—ì„œ ê°€ì§œë‰´ìŠ¤(Danger/Warning)ë¡œ íŒì •
                vision_result = thumbnail_analysis.get("vision_analysis", {})
                rating = vision_result.get("fake_news_rating", "Safe")
                
                if rating == "Danger":
                    image_contradiction_score = 1.0
                    logger.info(f"ğŸš¨ ê°€ì§œë‰´ìŠ¤ ì¸ë„¤ì¼ íƒì§€: ë“±ê¸‰=Danger")
                elif rating == "Warning":
                    image_contradiction_score = 0.5
                    logger.info(f"âš ï¸ ê°€ì§œë‰´ìŠ¤ ì¸ë„¤ì¼ ì˜ì‹¬: ë“±ê¸‰=Warning")
            else:
                # Stage 1 í†µê³¼ ë˜ëŠ” Safe
                image_contradiction_score = 0.0
                logger.info(f"âœ… ì¸ë„¤ì¼ ì •ìƒ: Stage={thumbnail_analysis.get('stage', 'unknown')}")

            # 4. frames ë°°ì—´ ìƒì„±
            frames = self._create_evidence_frames(
                thumbnail_text_result,
                thumbnail_analysis
            )

            # 5. ê²°ê³¼ ìš”ì•½ ìƒì„±
            summary = self._generate_module_summary(
                thumbnail_text_result,
                thumbnail_analysis,
                request.claims
            )

            # 6. ê²°ê³¼ ë§¤í•‘
            image_claims = []
            for claim in request.claims:
                image_claims.append(ClaimVerdict(
                    claim_id=claim.claim_id,
                    image_support_score=0.0, # ì´ë¯¸ì§€ ëª¨ë“ˆì€ íŒ©íŠ¸ì²´í¬ë³´ë‹¤ëŠ” ìê·¹ì„± ìœ„ì£¼
                    image_contradiction_score=image_contradiction_score,
                    notes=[summary],
                    frames=frames
                ))

            processing_time = (time.time() - start_time) * 1000
            logger.info(f"ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {processing_time:.2f}ms")

            return ImageModuleResult(
                modality="image",
                video_id=request.video_id,
                analysis_summary=summary,
                claims=image_claims,
                frames=frames,
                processing_time_ms=processing_time,
                status="success",
                overall_contradiction_score=image_contradiction_score
            )

        except Exception as e:
            logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}", exc_info=True)
            return ImageModuleResult(
                modality="image",
                video_id=request.video_id,
                analysis_summary=f"ì˜¤ë¥˜ ë°œìƒ: {str(e)}",
                claims=[],
                processing_time_ms=(time.time() - start_time) * 1000,
                status="error",
                error_message=str(e)
            )

    async def _analyze_thumbnail_text(self, image_url: str) -> Dict[str, Any]:
        """ì¸ë„¤ì¼ì˜ TEXT_DETECTION (OCR + í…ìŠ¤íŠ¸ í¬ê¸° ë¶„ì„)"""
        try:
            content = await asyncio.to_thread(self._download_image, image_url)
            if not content:
                raise Exception("Thumbnail download failed")

            image = vision.Image(content=content)

            # TEXT_DETECTION ìš”ì²­
            features = [vision.Feature(type_=vision.Feature.Type.TEXT_DETECTION)]
            request_obj = vision.AnnotateImageRequest(image=image, features=features)
            response = await asyncio.to_thread(self.vision_client.annotate_image, request=request_obj)

            if not response.text_annotations:
                return {
                    "extracted_text": "",
                    "text_size_ratio": 0.0,
                    "bounding_boxes": []
                }

            # ì²« ë²ˆì§¸ annotationì´ ì „ì²´ í…ìŠ¤íŠ¸
            full_text = response.text_annotations[0].description

            # ê° ë‹¨ì–´ì˜ bounding box ìˆ˜ì§‘
            bounding_boxes = []
            total_text_area = 0
            for annotation in response.text_annotations[1:]:  # ì²« ë²ˆì§¸ëŠ” ì „ì²´ í…ìŠ¤íŠ¸ë¼ì„œ ìŠ¤í‚µ
                vertices = annotation.bounding_poly.vertices
                if len(vertices) == 4:
                    width = abs(vertices[1].x - vertices[0].x)
                    height = abs(vertices[2].y - vertices[0].y)
                    area = width * height
                    total_text_area += area
                    bounding_boxes.append({
                        "text": annotation.description,
                        "area": area
                    })

            # ì´ë¯¸ì§€ í¬ê¸° ì¶”ì • (ì²« ë²ˆì§¸ annotationì˜ ì „ì²´ ì˜ì—­)
            if response.text_annotations:
                img_vertices = response.text_annotations[0].bounding_poly.vertices
                if len(img_vertices) == 4:
                    img_width = max(v.x for v in img_vertices)
                    img_height = max(v.y for v in img_vertices)
                    image_area = img_width * img_height if img_width > 0 and img_height > 0 else 1
                else:
                    image_area = 1280 * 720  # ê¸°ë³¸ê°’
            else:
                image_area = 1280 * 720

            # í…ìŠ¤íŠ¸ í¬ê¸° ë¹„ìœ¨ ê³„ì‚°
            text_size_ratio = min(total_text_area / image_area, 1.0) if image_area > 0 else 0.0

            logger.info(f"OCR ì™„ë£Œ: í…ìŠ¤íŠ¸ ê¸¸ì´={len(full_text)}, í¬ê¸°ë¹„ìœ¨={text_size_ratio:.2%}")

            return {
                "extracted_text": full_text,
                "text_size_ratio": text_size_ratio,
                "bounding_boxes": bounding_boxes
            }

        except Exception as e:
            logger.error(f"ì¸ë„¤ì¼ TEXT_DETECTION ì‹¤íŒ¨: {e}")
            raise

    def _check_clickbait_keywords(self, text: str) -> Dict[str, Any]:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ë§¤ì¹­ìœ¼ë¡œ ë‚šì‹œì„± ì²´í¬"""
        if not text:
            return {
                "has_clickbait": False,
                "matched_keywords": [],
                "reason": "í…ìŠ¤íŠ¸ ì—†ìŒ"
            }

        # í‚¤ì›Œë“œ ë§¤ì¹­
        matched = [kw for kw in CLICKBAIT_KEYWORDS if kw in text]

        return {
            "has_clickbait": len(matched) > 0,
            "matched_keywords": matched,
            "reason": f"ë‚šì‹œì„± í‚¤ì›Œë“œ {len(matched)}ê°œ ë°œê²¬: {', '.join(matched)}" if matched else "ë‚šì‹œì„± í‚¤ì›Œë“œ ì—†ìŒ"
        }

    async def _analyze_thumbnail_with_vision(
        self,
        image_url: str,
        extracted_text: str,
        matched_keywords: List[str]
    ) -> Dict[str, Any]:
        """GPT-4o-mini Visionìœ¼ë¡œ ì¸ë„¤ì¼ ì‹¬ì¸µ ë¶„ì„ (Stage 2)"""
        try:
            from ..shared.llm_client import LLMClient
            import json

            # GPT-4o-mini ì‚¬ìš© (ë¹„ìš© ì ˆê°)
            llm = LLMClient(model="gpt-4o-mini")

            prompt = get_thumbnail_analysis_prompt(extracted_text, matched_keywords)

            # GPT-4o-mini Vision API í˜¸ì¶œ
            messages = [{
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": image_url}}
                ]
            }]

            response_text = await llm.chat_completion_image(
                messages=messages,
                temperature=0.3,
                max_tokens=500
            )

            # JSON íŒŒì‹±
            try:
                # LLM ì‘ë‹µì—ì„œ JSON ë¸”ë¡ë§Œ ì¶”ì¶œ
                json_match = re.search(r'```json\n({.*?})\n```', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    json_str = response_text

                result = json.loads(json_str.strip())
                logger.info(f"âœ… GPT Vision ë¶„ì„ ì™„ë£Œ: rating={result.get('fake_news_rating', 'unknown')}, style={result.get('design_style', 'unknown')}")
                return result
            except json.JSONDecodeError as e:
                logger.error(f"GPT Vision JSON íŒŒì‹± ì‹¤íŒ¨: {e}. ì‘ë‹µ: {response_text}")
                return {
                    "text_density": "unknown",
                    "design_style": "unknown",
                    "emotion": "unknown",
                    "fake_news_rating": "Warning", # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
                    "reason": f"ë¶„ì„ ì˜¤ë¥˜: LLM ì‘ë‹µì´ ìœ íš¨í•œ JSONì´ ì•„ë‹˜"
                }

        except Exception as e:
            logger.error(f"GPT Vision ë¶„ì„ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {e}", exc_info=True)
            return {
                "text_density": "unknown",
                "design_style": "unknown",
                "emotion": "unknown",
                "fake_news_rating": "Warning",
                "reason": f"ë¶„ì„ ì˜¤ë¥˜: {str(e)}"
            }



    def _download_image(self, url: str) -> Optional[bytes]:
        try:
            resp = requests.get(url, timeout=10)
            return resp.content if resp.status_code == 200 else None
        except:
            return None

    def _create_evidence_frames(
        self,
        thumbnail_data: Dict,
        thumbnail_analysis: Dict
    ) -> List[Dict]:
        """ì¦ê±° í”„ë ˆì„ ë°°ì—´ ìƒì„±"""
        frames = []

        # ì¸ë„¤ì¼ í”„ë ˆì„ ì¶”ê°€
        if thumbnail_data.get("extracted_text"):
            is_fake = thumbnail_analysis.get("is_fake", False)
            stage = thumbnail_analysis.get("stage", "unknown")

            details = {
                "stage": stage,
                "text_size_ratio": thumbnail_data.get("text_size_ratio", 0.0),
                "matched_keywords": thumbnail_analysis.get("matched_keywords", [])
            }

            # Stage 2 Vision ë¶„ì„ ê²°ê³¼ í¬í•¨
            if stage == "stage2_vision":
                vision = thumbnail_analysis.get("vision_analysis", {})
                details.update({
                    "text_density": vision.get("text_density", "unknown"),
                    "design_style": vision.get("design_style", "unknown"),
                    "emotion": vision.get("emotion", "no"),
                    "fake_news_rating": vision.get("fake_news_rating", "Safe")
                })

            frames.append({
                "frame_id": "thumbnail",
                "timestamp": 0.0,
                "description": "ì¸ë„¤ì¼ 2ë‹¨ê³„ ë¶„ì„",
                "evidence": thumbnail_data["extracted_text"][:200],
                "is_problematic": is_fake,
                "details": details
            })

        return frames

    def _generate_module_summary(
        self,
        thumbnail_data: Dict,
        thumbnail_analysis: Dict,
        claims: List[Claim]
    ) -> str:
        """ìƒì„¸ ë¶„ì„ ê²°ê³¼ ìš”ì•½ ìƒì„±"""
        summary_parts = []

        # 1. ì¸ë„¤ì¼ OCR ê²°ê³¼
        if "error" in thumbnail_data:
            summary_parts.append(f"âš ï¸ ì¸ë„¤ì¼ ë¶„ì„ ì˜¤ë¥˜: {thumbnail_data['error']}")
        else:
            extracted_text = thumbnail_data.get("extracted_text", "")
            text_size_ratio = thumbnail_data.get("text_size_ratio", 0.0)

            if extracted_text:
                summary_parts.append(f"[ì¸ë„¤ì¼ OCR ê²°ê³¼]")
                summary_parts.append(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {extracted_text[:100]}...")
                summary_parts.append(f"í…ìŠ¤íŠ¸ ì ìœ ìœ¨: {text_size_ratio:.1%}")
            else:
                summary_parts.append("âš ï¸ ì¸ë„¤ì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        # 2. 2ë‹¨ê³„ ë¶„ì„ ê²°ê³¼
        stage = thumbnail_analysis.get("stage", "unknown")
        is_fake = thumbnail_analysis.get("is_fake", False)
        reason = thumbnail_analysis.get("reason", "")

        if stage == "stage1_pass":
            summary_parts.append(f"\nâœ… [Stage 1 í†µê³¼]")
            summary_parts.append(f"íŒì •: ì •ìƒ (í…ìŠ¤íŠ¸ 20% ë¯¸ë§Œ, ìê·¹ì  í‚¤ì›Œë“œ ì—†ìŒ)")

        elif stage == "stage2_vision":
            vision = thumbnail_analysis.get("vision_analysis", {})
            rating = vision.get("fake_news_rating", "Safe")

            if rating in ["Danger", "Warning"]:
                icon = "ğŸš¨" if rating == "Danger" else "âš ï¸"
                summary_parts.append(f"\n{icon} [Stage 2: ê°€ì§œë‰´ìŠ¤ íƒì§€]")
                summary_parts.append(f"ìœ„í—˜ ë“±ê¸‰: {rating}")
                summary_parts.append(f"ë””ìì¸ ìŠ¤íƒ€ì¼: {vision.get('design_style', 'unknown')}")
                summary_parts.append(f"í…ìŠ¤íŠ¸ ë°€ë„: {vision.get('text_density', 'unknown')}")
                summary_parts.append(f"í‘œì • ê³¼ì¥: {vision.get('emotion', 'no')}")
                summary_parts.append(f"íŒì • ì´ìœ : {reason}")
            else:
                summary_parts.append(f"\nâœ… [Stage 2: ì •ìƒ]")
                summary_parts.append(f"ìœ„í—˜ ë“±ê¸‰: Safe")

        elif stage == "stage1_borderline":
            summary_parts.append(f"\nâœ… [Stage 1 ê²½ê³„ ì¼€ì´ìŠ¤]")
            summary_parts.append(f"íŒì •: ì •ìƒ (ê¸°ì¤€ ë¯¸ë‹¬)")

        else:
            summary_parts.append(f"\nâš ï¸ [ì•Œ ìˆ˜ ì—†ìŒ] stage={stage}")

        return "\n".join(summary_parts)